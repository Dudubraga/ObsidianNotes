---
tags:
  - unicap
  - gradua√ß√£o
  - 6-periodo
---

**Professor:** Jheymesson Apolin√°rio
**Per√≠odo:** Ago 2025 - Dez 2025
**Nota final:** TBA

#### Projeto 1GQ: 
- Tema: Data Streaming
	- [[Arquitetura de Sistemas - Projeto Data Streaming em Tempo Real com Apache Kafka.pdf| Slides Data Streaming com Apache Kafka]]
- Nota: 10
#### Prova 1GQ:
- [[Arquitetura de Sistemas - Resumo 1GQ (Ana Bia).pdf| Resumo de Ana Bia]]
- [[Arquitetura de Sistemas - Resumo 1GQ (Bela).pdf| Resumo de Bela]]
- Nota: 6.5
#### Nota 1GQ: 
- (10 * 2 + 6.5 * 8) / 10 =

#### Projeto 2GQ: 
- Tema: Micros servi√ßo: **Laborat√≥rio & Diagn√≥sticos**
	- **Responsabilidades:** requisi√ß√µes e resultados de exames (estrutura HL7/FHI Obs), laudos, workflows e valida√ß√£o.
	- **Banco:** MongoDB (variabilidade de resultados) + S3 (PDFs).
	- **API:** /lab-orders, /lab-results.
	- **Eventos:** LabOrderCreated, LabResultAvailable.
- Nota: XX
#### Prova 2¬∫ GQ:
- [[Arquitetura de Sistemas - Resumo 2GQ.pdf]]
- Nota: XX
#### Nota 2¬∫ GQ: 
- (nota_proj * peso_proj + nota_prova * peso_prova) / 10 = 

#### M√©dia final:
- (nota_1GQ * 2 + nota_2GQ * 3) / 5 =

---

### Prova Final: (resumo)
#### üèõÔ∏è Parte 1: Fundamentos de Sistemas Distribu√≠dos
**O Conceito:** V√°rios computadores independentes que parecem um s√≥ para o usu√°rio.
- **Centralizado (Mainframe):** F√°cil gest√£o, **Ponto √önico de Falha**, escalabilidade vertical (cara e limitada) .
- **Distribu√≠do:** Escalabilidade **Horizontal** (mais m√°quinas baratas), toler√¢ncia a falhas, mas traz **complexidade** de rede e consist√™ncia.
**Comunica√ß√£o Interna:**
- **Processos:** Mem√≥ria isolada, pesados, seguros.
- **Threads:** Mem√≥ria compartilhada, leves, risco de **Race Conditions** (condi√ß√£o de corrida).
**Comunica√ß√£o em Rede:**
- **S√≠ncrona (Bloqueante):** Cliente espera a resposta. Gera **Acoplamento Temporal**. Ex: Login.
- **Ass√≠ncrona (N√£o-bloqueante):** Cliente manda e segue a vida ("fire-and-forget"). Usa filas. Gera **Resili√™ncia**. Ex: Processamento de v√≠deo.
**Teorema CAP e Consist√™ncia:**
- **Forte:** Todos veem o mesmo dado na hora. Bom para **Bancos**. (Sacrifica Disponibilidade na falha).
- **Eventual:** Dados convergem com o tempo. Bom para **Redes Sociais**. (Prioriza Disponibilidade).
- **Causal:** Garante a ordem apenas de eventos relacionados (causa e efeito). Eventos sem rela√ß√£o podem ser vistos em qualquer ordem. Uso: **Chats e F√≥runs** (Para n√£o ver a resposta antes da pergunta).
**Falhas:**
- **Tipos:** Crash (morreu), Omiss√£o (perdeu pacote), Temporais (demora demais), Bizantina (mentiu/maluco).
- **Recupera√ß√£o:** 
	- **Retry:** Tentar de novo com tempo crescente (**Backoff**) + sorteio (**Jitter**).
	- **Checkpoint + Log:** Salva o estado grosso (**Check**) + o hist√≥rico fino (**Log**) para reconstruir.
	- **Failover:** Um morre, o reserva assume (**Ativo-Passivo**).
	- **Fallback:** Se n√£o der pra fazer o ideal, entregue o b√°sico (**Cache/Default**).

#### üõ°Ô∏è Parte 2: Seguran√ßa
**Controle de Acesso:**
- **RBAC:** Baseado no **Cargo** (Est√°tico). O "Crach√°".
- **ABAC:** Baseado em **Atributos** (Contexto: hora, local). O "Porteiro chato".
- **PBAC:** Baseado em **Pol√≠ticas** (Regras l√≥gicas). Governan√ßa centralizada.
**Criptografia:**
- **Sim√©trica:** Uma chave (r√°pida). Problema: Como entregar a chave?
- **Assim√©trica:** Duas chaves (P√∫blica/Privada). Resolve a troca, mas √© lenta.
- **H√≠brida:** Assim√©trica no come√ßo (troca segredo) + Sim√©trica depois (velocidade). Base do **HTTPS**.
**Zero Trust:** "Nunca confie, sempre verifique". Seguran√ßa em cada requisi√ß√£o, n√£o s√≥ na borda.

#### Parte 3: Arquitetura de Servi√ßos
**SOA (O Av√¥):**
- Foco em reuso. Depende do **ESB** (Enterprise Service Bus).
- **Problema:** O ESB virou gargalo ("Smart pipes", cano inteligente demais) e burocracia.
**Microsservi√ßos (O Neto √Ågil):**
- **Database-per-service** (Banco exclusivo por servi√ßo = Desacoplamento).
- Filosofia: "Smart endpoints, dumb pipes". Autonomia de times.
**A Trindade dos Protocolos:**
- **SOAP:** Baseado em XML e contratos r√≠gidos (WSDL). Foco em seguran√ßa/formalidade. Ex: Transa√ß√µes banc√°rias/ERP.
- **REST:** Baseado em Recursos e HTTP/JSON. Flex√≠vel e leve. Ex: APIs P√∫blicas e Web/Mobile.
- **gRPC:** Baseado em Bin√°rio (Protobuf) e HTTP/2. Alta performance. Ex: Comunica√ß√£o interna entre microsservi√ßos.

#### Parte 4: Nuvem e Infraestrutura
**Containers (A "Mentira" do S.O.):**
- N√£o √© VM! √â processo isolado.
- **Namespaces:** Isola a vis√£o (o que eu vejo).
- **Cgroups:** Limita o recurso (quanto eu gasto de CPU/RAM).
- **Dockerfile:** `FROM` (base), `RUN` (instala), `COPY` (copia arq), `CMD` (executa).
**Modelos de Nuvem:**
- **IaaS:** Eu cuido do **S.O.** pra cima (AWS EC2).
- **PaaS:** Eu cuido s√≥ do **C√≥digo** e Dados (Heroku).
- **SaaS:** Eu cuido s√≥ do **Acesso/Config** (Gmail).
**Deploy:**
- **Recreate:** Desliga tudo, liga o novo. Tem **Downtime**.
- **Rolling Update:** Troca gradualmente. Sem downtime, rollback lento.
- **Blue-Green:** Troca instant√¢nea de ambiente. Rollback r√°pido, custo dobro.
- **Canary:** Testa com 1% dos usu√°rios. Seguran√ßa no teste.

---
### Prova Final: (simulado)
**Quest√£o 1: Em sistemas distribu√≠dos, existe um teorema famoso chamado CAP (Consist√™ncia, Disponibilidade e Toler√¢ncia a Parti√ß√£o). Explique por que, em um sistema distribu√≠do sujeito a falhas de rede (Parti√ß√£o), somos obrigados a escolher entre Consist√™ncia e Disponibilidade. Diferencie, nesse contexto, o modelo de Consist√™ncia Forte do modelo de Consist√™ncia Eventual, dando um exemplo de onde usar cada um.**
> (Dica: Lembre-se do banco vs. rede social).

- Em sistemas distribu√≠dos, a falha de rede (Parti√ß√£o) √© inevit√°vel. Quando ela ocorre, os n√≥s n√£o conseguem sincronizar seus estados. Pelo Teorema CAP, somos obrigados a escolher: ou bloqueamos o sistema para garantir que os dados n√£o divirjam (priorizando Consist√™ncia em detrimento da Disponibilidade), ou permitimos que o sistema continue respondendo, mesmo com dados potencialmente desatualizados (priorizando Disponibilidade).
	- **Consist√™ncia Forte:** Garante que qualquer leitura retorne o valor mais recente de escrita, agindo como se fosse um n√≥ √∫nico. √â ideal para cen√°rios cr√≠ticos como **transa√ß√µes financeiras**, onde o erro n√£o √© tolerado.
	- **Consist√™ncia Eventual:** √â um modelo mais flex√≠vel onde, na aus√™ncia de novas escritas, os dados eventualmente convergir√£o. Aceita-se inconsist√™ncia tempor√°ria em troca de alta disponibilidade e escalabilidade, sendo ideal para **redes sociais** (ex: contagem de likes).

**Quest√£o 2: A comunica√ß√£o define a alma do sistema distribu√≠do. Compare o modelo de comunica√ß√£o S√≠ncrona (como RPC/REST) com a comunica√ß√£o Ass√≠ncrona (como Mensageria/Filas). Explique como a escolha pela comunica√ß√£o ass√≠ncrona ajuda a resolver o problema do Acoplamento Temporal e aumenta a resili√™ncia do sistema, citando um exemplo pr√°tico de uso.**
> (Dica: Pense no que acontece se o servi√ßo de "Estoque" cair enquanto voc√™ tenta fechar uma venda).

- Na **Comunica√ß√£o S√≠ncrona**, o cliente envia a requisi√ß√£o e fica **bloqueado** aguardando a resposta. Isso cria um **Acoplamento Temporal**: cliente e servidor precisam estar online simultaneamente. √â ideal para opera√ß√µes de login, onde a resposta imediata √© mandat√≥ria.
- J√° na **Comunica√ß√£o Ass√≠ncrona**, o cliente envia a mensagem para uma fila e segue seu trabalho (**fire-and-forget**). Isso resolve o **Acoplamento Temporal**, pois o receptor n√£o precisa estar ativo no momento do envio. Aumenta a **resili√™ncia** porque, se o servi√ßo consumidor cair ou estiver sobrecarregado, a mensagem fica segura na fila at√© ser processada, evitando a perda de dados.

**Quest√£o 3: A arquitetura de Microsservi√ßos prega a descentraliza√ß√£o. Explique o conceito de "Database-per-service" (Banco de dados por servi√ßo) e por que ele √© fundamental para garantir o desacoplamento e a autonomia das equipes, diferenciando essa abordagem da arquitetura Monol√≠tica tradicional que usa um banco compartilhado. Quais os desafios que isso traz para transa√ß√µes que envolvem m√∫ltiplos servi√ßos?**
> (Dica: Lembre-se da nossa cozinha. Se todo mundo usar a mesma t√°bua de cortar carne, vira bagun√ßa).

- O padr√£o **Database-per-service** funciona como se cada esta√ß√£o da cozinha (Grelha, Salada, Sobremesa) tivesse sua pr√≥pria geladeira exclusiva (**Desacoplamento de Dados**). No modelo tradicional, todos usavam uma √∫nica geladeira gigante. Se algu√©m mudasse a organiza√ß√£o das prateleiras, o cozinheiro da chapa poderia n√£o achava mais a carne e a cozinha parava (**Alto Acoplamento**). Al√©m disso, todos disputavam a mesma porta, criando um **gargalo**. A solu√ß√£o foi que cada microsservi√ßo gerencia seus pr√≥prios dados. O gar√ßom n√£o pode abrir a geladeira do cozinheiro, ele precisa pedir o prato pronto via uma 'comanda' (**API**). Isso garante **autonomia** e evita que uma mudan√ßa interna quebre outros servi√ßos .
- O problema surge quando um pedido exige itens de v√°rias esta√ß√µes (ex: Bife com Fritas). No mon√≥lito, o chef garantia que **tudo sa√≠a junto ou nada sa√≠a**. Nos microsservi√ßos, como as geladeiras s√£o separadas, n√£o temos esse controle centralizado imediato. Se a batata acabar depois que o bife j√° foi para a chapa, precisamos avisar a grelha para parar ou jogar o bife fora. Resolvemos isso com a√ß√µes compensat√≥rias para garantir a consist√™ncia eventual.

**Quest√£o 4: Muita gente confunde Container com M√°quina Virtual. Teoricamente, um container √© um processo isolado que "mente" para o sistema operacional. Explique o papel dos Namespaces e dos Cgroups (Control Groups) no Linux para criar esse isolamento. O que cada um deles controla especificamente para garantir que um container n√£o derrube o vizinho?**
> (Dica: Um isola a vis√£o, o outro limita o uso).

- Ao contr√°rio do senso comum, um container n√£o √© uma mini m√°quina virtual. √â um processo isolado no sistema operacional do host. O kernel do Linux usa **Namespaces** para enganar o processo, fazendo com que ele **acredite que √© o √∫nico na m√°quina**. Ele tem sua pr√≥pria √°rvore de processos e sua pr√≥pria rede e o processo dentro do container n√£o enxerga os processos do host. J√° os **Cgroups**, **limitam o uso de CPU e mem√≥ria** do grupo de processos. Isso serve para impedir que um container drene todos os recursos do servidor, prejudicando a qualidade de servi√ßo para os processos vizinhos.

**Quest√£o 5: Voc√™ precisa atualizar um sistema cr√≠tico de pagamentos onde o risco de bugs √© inaceit√°vel. Compare as estrat√©gias de deploy Blue-Green e Canary Release. Qual delas oferece o rollback mais r√°pido e qual oferece a maior seguran√ßa ao testar a nova vers√£o com tr√°fego real (mas reduzido)? Justifique sua escolha para esse cen√°rio financeiro.**
> (Dica: Pense em custo de infraestrutura versus seguran√ßa de teste).

- Para um sistema cr√≠tico de pagamentos, a estrat√©gia **Blue-Green** √© a melhor escolha para o **Rollback**, pois permite reverter instantaneamente 100% do tr√°fego para a vers√£o est√°vel em caso de falha, bastando alterar o roteamento. Embora tenha o custo elevado de duplicar a infraestrutura, isso √© justific√°vel para evitar preju√≠zo financeiro.
- Contudo, √© importante notar que o **Canary Release** ofereceria maior seguran√ßa ao **testar com tr√°fego real**, pois **limita o impacto de um erro** a uma pequena fra√ß√£o de usu√°rios. No **Blue-Green**, o risco √© 'tudo ou nada', se houver um bug que passou pelos testes internos, ele **afetar√° todos os usu√°rios simultaneamente** assim que a chave for virada.

**Quest√£o Extra: Diferencie os modelos de controle de acesso RBAC (Role-Based Access Control) e ABAC (Attribute-Based Access Control). Qual deles oferece maior granularidade e dinamismo para um sistema que precisa restringir acesso baseado no hor√°rio e na localiza√ß√£o do usu√°rio, e por qu√™?**
> (Dica: O crach√° do porteiro vs. regras de contexto).

- O modelo **RBAC** (Baseado em Pap√©is) concede acesso com base na fun√ß√£o est√°tica do usu√°rio (ex: um 'Gerente' tem acesso total), o que simplifica a administra√ß√£o, mas carece de flexibilidade contextual. 
- J√° o modelo **ABAC** (Baseado em Atributos) oferece muito maior **granularidade e dinamismo**, pois avalia n√£o apenas quem √© o usu√°rio, mas tamb√©m o **contexto** da requisi√ß√£o (como hor√°rio, localiza√ß√£o geogr√°fica e dispositivo). 
- Portanto, para um sistema que precisa restringir acesso baseado em **hora e local**, o **ABAC** √© a √∫nica escolha vi√°vel, pois permite criar pol√≠ticas condicionais ('Se for depois das 18h, negue'), algo que o RBAC tradicional n√£o consegue fazer nativamente.

--- 

### Prova 2GQ: Microsservi√ßos
#### 1. Seguran√ßa e Controle de Acesso: A Fortaleza Digital
Come√ßamos discutindo como proteger nosso castelo. N√£o adianta ter paredes altas se o porteiro deixa qualquer um entrar, certo? Falamos sobre **Controle de Acesso**, diferenciando modelos cl√°ssicos. Vimos o **RBAC** (Role-Based Access Control), onde as permiss√µes s√£o atreladas ao cargo do sujeito, e o **ABAC** (Attribute-Based Access Control), que √© mais sofisticado e olha para atributos como hor√°rio, local e departamento. Discutimos tamb√©m a **Criptografia**. Lembra da hist√≥ria da Enigma e dos nazistas? Pois √©, a base te√≥rica aqui √© entender a diferen√ßa entre a criptografia **Sim√©trica** (r√°pida, chave √∫nica, mas com o problema da distribui√ß√£o da chave) e a **Assim√©trica** (chaves p√∫blica/privada, resolve a distribui√ß√£o, mas √© lenta). O segredo do sucesso na web hoje √© a **H√≠brida**, que junta o melhor dos dois mundos.
#### 2. Webservices e a Comunica√ß√£o Distribu√≠da
Depois, entramos no mundo da comunica√ß√£o entre sistemas. Como fazer componentes diferentes conversarem sem virar uma Torre de Babel? Estudamos os **Webservices**. Analisamos o **SOAP**, aquele "velho guerreiro" burocr√°tico baseado em XML e contratos r√≠gidos, √≥timo para bancos. Comparamos com o **REST**, que √© o "jovem descolado" da web, usando verbos HTTP e JSON, focado em recursos. E n√£o esquecemos do **gRPC**, o "ligeirinho" da Google, que usa bin√°rio e Protobuf, perfeito para conversas internas r√°pidas. A grande li√ß√£o aqui √© entender os _trade-offs_ de cada um: complexidade vs. simplicidade, verbosidade vs. performance.
#### 3. SOA vs. Microsservi√ßos: A Evolu√ß√£o da Esp√©cie
Aqui a coisa ficou s√©ria! Falamos da **SOA** (Service-Oriented Architecture). A SOA trouxe a ideia de servi√ßos aut√¥nomos e reutiliz√°veis, muitas vezes orquestrados por um barramento (ESB). Mas a evolu√ß√£o nos levou aos **Microsservi√ßos**. A diferen√ßa crucial te√≥rica √© o acoplamento e a governan√ßa. Nos microsservi√ßos, focamos em "Smart endpoints and dumb pipes" (pontas inteligentes e canos burros), evitando a l√≥gica centralizada do ESB. Tamb√©m batemos forte no **DDD** (Domain-Driven Design), usando conceitos como _Bounded Contexts_ para definir onde termina um servi√ßo e come√ßa outro, garantindo que a divis√£o seja pelo neg√≥cio e n√£o pela tecnologia.
#### 4. O Mundo dos Containers
Saindo da abstra√ß√£o total para a virtualiza√ß√£o, explicamos o que _realmente_ √© um container. Esque√ßa o comando `docker run` por um minuto. Teoricamente, um container √© uma mentira bem contada pelo Sistema Operacional, usando **Namespaces** para isolar o que o processo _v√™_ (rede, processos, sistema de arquivos) e **Cgroups** para limitar o que o processo _usa_ (CPU, mem√≥ria). Entendemos que uma imagem n√£o √© m√°gica, √© apenas um sistema de arquivos em camadas (UnionFS) imut√°veis. Essa base te√≥rica √© o que permite a portabilidade e a efici√™ncia que tanto amamos, sem o peso de uma m√°quina virtual completa.
#### 5. Arquitetura em Nuvem e Escalabilidade
Por fim, olhamos para as nuvens. Discutimos os modelos de servi√ßo (**IaaS, PaaS, SaaS**) e como a responsabilidade de gerenciamento muda em cada um. Aprofundamos em **Estrat√©gias de Deploy**, porque subir c√≥digo n√£o √© s√≥ "dar play". Vimos o **Blue-Green** (troca instant√¢nea, risco baixo, custo alto de infra) , o **Canary** (testar com um pouquinho de gente antes de liberar pra geral) e o **Rolling Update** (troca gradual, sem downtime, mas lento para rollback). Fechamos com a trindade da **Observabilidade**: Logs (o que aconteceu?), M√©tricas (quanto est√° acontecendo?) e Tracing (onde diabos est√° o problema?).

---
### Projeto 2GQ: Laborat√≥rio & Diagn√≥sticos 
#### üë©‚Äçüíª Integrante 1: Isabela (A "Especialista em Cloud")

* **Responsabilidade:** Endpoint `LabReports` (`POST /lab-results/<string:result_id>/report`).
* **O que pode falar:**
    * Explicar que essa rota √© respons√°vel por receber o **laudo (um arquivo PDF)** e conect√°-lo a um resultado de exame que j√° existe no banco.
    * Mostrar no c√≥digo a valida√ß√£o para garantir que um arquivo foi realmente enviado (`if 'file' not in request.files:`).
    * Mencionar o uso da biblioteca `werkzeug` com `secure_filename` para tratar o nome do arquivo, uma pr√°tica importante de seguran√ßa para evitar ataques de *directory traversal*.
    * Explicar como a conex√£o com a AWS √© feita usando a biblioteca `boto3`.
    * Destacar que as credenciais e o nome do *bucket* S3 n√£o est√£o no c√≥digo, mas sim em **vari√°veis de ambiente** (`os.getenv`), como definido no `docker-compose.yml`, o que √© uma boa pr√°tica.
    * Mostrar a linha `s3.upload_fileobj(...)`, que √© o comando que efetivamente envia o arquivo para o *bucket* S3.
    * Explicar a parte final e crucial: `lab_results.update_one(...)`. Ap√≥s o upload, o c√≥digo **atualiza o documento no MongoDB** para adicionar a `report_url`, ligando o dado estruturado (resultado) ao dado n√£o estruturado (o PDF no S3).
* **Ponto de Orgulho (O que "mais se orgulha"):**
    > "O que mais me orgulho foi de implementar exatamente o que a arquitetura do projeto pedia para o nosso m√≥dulo: o uso de **MongoDB para os metadados** dos exames e **S3 para os laudos em PDF**. Consegui fazer a API receber um arquivo de forma segura, envi√°-lo para o S3 e, o mais importante, atualizar o documento no Mongo com a URL do laudo, fechando o ciclo de dados do paciente."

---

#### üë®‚Äçüíª Integrante 2: (Sugest√£o: J√∫lia) - Os Endpoints de Consulta (`GET`s)

* **Responsabilidade:** `GET /lab-orders` e `GET /lab-results`.
* **O que pode falar:**
    * Explicar que esses dois *endpoints* s√£o as "portas de leitura" do microservi√ßo.
    * O ponto principal aqui √© a **ader√™ncia ao padr√£o FHIR**. A proposta do projeto exige o uso de HL7/FHIR.
    * Mostrar que o c√≥digo n√£o retorna o dado "cru" do MongoDB. Em vez disso, ele **transforma os dados** para o formato FHIR.
    * No `GET /lab-orders`, mostrar como os campos do Mongo (`patient_id`, `exam_type`, `status`) s√£o mapeados para um recurso FHIR `ServiceRequest`.
    * No `GET /lab-results`, mostrar o mapeamento similar para um recurso FHIR `Observation`.
    * Mencionar a fun√ß√£o auxiliar `serialize_id` como um detalhe t√©cnico necess√°rio para converter o `ObjectId` do Mongo em uma *string* JSON leg√≠vel.
* **Ponto de Orgulho (O que "mais se orgulha"):**
    > "Minha responsabilidade foi garantir que, apesar de usarmos MongoDB internamente, nossa API 'fala' a l√≠ngua universal da sa√∫de, o **FHIR**. O que mais me orgulho √© a **camada de transforma√ß√£o** que criei nos m√©todos `GET`. N√£o estamos apenas 'cuspindo' dados do banco; estamos formatando-os como recursos `ServiceRequest` e `Observation`. Isso torna nosso microservi√ßo interoper√°vel e pronto para se conectar com qualquer outro sistema hospitalar que siga o mesmo padr√£o."

---

#### üë®‚Äçüíª Integrante 3: (Sugest√£o: Eduardo) - Cria√ß√£o de Pedidos e Eventos (`POST /lab-orders`)

* **Responsabilidade:** `POST /lab-orders`.
* **O que pode falar:**
    * Explicar que este *endpoint* √© o **ponto de partida** de todo o fluxo de trabalho do laborat√≥rio.
    * Mostrar a valida√ß√£o de *payload* (verificando se `patient_id` e `exam_type` foram enviados).
    * Explicar a cria√ß√£o do documento no MongoDB com o `status` inicial `"requested"`.
    * **Ponto-chave:** Focar na parte de **Arquitetura Orientada a Eventos (EDA)**.
    * Mostrar a linha `events.insert_one(...)` e explicar que, al√©m de salvar o pedido, o servi√ßo **publica um evento** (`LabOrderCreated`).
    * Explicar *por que* isso √© importante: outros microservi√ßos (como o de Faturamento ou Notifica√ß√µes) podem "ouvir" esse evento e iniciar seus pr√≥prios processos, sem que o nosso servi√ßo de laborat√≥rio precise saber que eles existem. Isso se chama **baixo acoplamento**.
* **Ponto de Orgulho (O que "mais se orgulha"):**
    > "Fiquei com o in√≠cio do nosso fluxo, a cria√ß√£o do pedido de exame. O ponto principal do meu c√≥digo, e do que mais me orgulho, n√£o √© apenas salvar o pedido no banco. √â a implementa√ß√£o da **arquitetura orientada a eventos**. Ao criar o pedido, eu tamb√©m disparo um evento `LabOrderCreated` na cole√ß√£o de eventos. Isso √© a base da arquitetura de microservi√ßos: nosso servi√ßo avisa o que fez, e outros podem reagir a isso sem que a gente precise se acoplar a eles."

---

#### üë©‚Äçüíª Integrante 4: (Sugest√£o: Henrique) - Registro de Resultados e L√≥gica de Neg√≥cio (`POST /lab-results`)

* **Responsabilidade:** `POST /lab-results`.
* **O que pode falar:**
    * Explicar que este √© o *endpoint* mais complexo, pois ele **fecha o ciclo** do exame e coordena dados entre diferentes cole√ß√µes.
    * **Valida√ß√£o Robusta:** Mostrar que o c√≥digo valida n√£o apenas o *payload* (os campos obrigat√≥rios), mas tamb√©m o `order_id`. Ele verifica se o ID √© um `ObjectId` v√°lido e, em seguida, se **o pedido realmente existe** (`lab_orders.find_one`). Isso evita que "resultados √≥rf√£os" sejam criados.
    * **Enriquecimento de Dados:** Apontar que o `patient_id` √© copiado do pedido original para o documento de resultado, garantindo a integridade referencial.
    * **Conclus√£o do Workflow:** Explicar as tr√™s a√ß√µes que acontecem em sequ√™ncia:
        1.  Salva o resultado (`lab_results.insert_one`).
        2.  Dispara o evento `LabResultAvailable` (assim como o Integrante 3, mostrando a consist√™ncia da arquitetura).
        3.  **Atualiza o pedido original:** Usa `lab_orders.update_one` para mudar o `status` do pedido de `"requested"` para `"completed"`.
* **Ponto de Orgulho (O que "mais se orgulha"):**
    > "Minha fun√ß√£o foi registrar o resultado do exame, o que completa o fluxo iniciado pelo pedido. O que mais me orgulho √© a **l√≥gica de coordena√ß√£o e consist√™ncia de dados**. O c√≥digo n√£o apenas salva o resultado; ele primeiro **valida se o pedido original existe** para evitar dados √≥rf√£os. Em seguida, ele dispara o evento `LabResultAvailable` e, o mais importante, ele **'volta' na cole√ß√£o de pedidos e atualiza o status** daquele pedido para `completed`. Isso garante que o estado do nosso sistema permane√ßa consistente."

---
